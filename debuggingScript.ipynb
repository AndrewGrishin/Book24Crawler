{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Requests.response object\n",
    "def get_resp(url, params=None):\n",
    "    ua = UserAgent()\n",
    "    if params is None:\n",
    "        params = dict()\n",
    "    headers = {'User-Agent': ua.random}\n",
    "    resp = requests.get(url, params=params, headers=headers)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bs4 object to the passed url\n",
    "def get_soup(url, params=None):\n",
    "    resp = get_resp(url, params=params)\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all links to books from webpage\n",
    "def get_books_links_from_page(soup, scheme):\n",
    "    links = soup.select('div.product-card__image-holder > a')\n",
    "    links = list(map(lambda link: scheme + link['href'], links))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all info about one book from its page\n",
    "def get_single_book_data(soup, url, scheme):\n",
    "    data = dict()\n",
    "\n",
    "    # selectors for gathering required data\n",
    "    selectors = {\n",
    "        'classification': 'ol[itemscope=itemscope] span[itemprop=name]',\n",
    "        'description': 'div#product-characteristic > dl.product-characteristic__list',\n",
    "        'abstract': 'div.product-about.product-detail-page__product-about > div.product-about__text',\n",
    "        'side_bar': 'div.product-sidebar.product-detail-page__sidebar',\n",
    "        'vendor_code': 'p.product-detail-page__article',\n",
    "        'rating': 'div.product-ratings-widget',   \n",
    "    }\n",
    "    \n",
    "    # get classification block of book\n",
    "    classification = soup.select(selectors['classification'])\n",
    "    data['Классификация'] = []\n",
    "    try:\n",
    "        classification = list(map(lambda x: x.text.strip(), classification[1:]))\n",
    "        title = classification[-1]\n",
    "        data['Название'] = title\n",
    "        data['Классификация'] = classification[:-1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # get description block\n",
    "    description = soup.select_one(selectors['description'])\n",
    "    try:\n",
    "        characteristics = description.find_all('div')\n",
    "\n",
    "        for element in characteristics:\n",
    "            key = element.select_one('dt.product-characteristic__label-holder')\n",
    "            key = key.get_text().replace(':', '').strip()\n",
    "\n",
    "            value = element.select_one('dd.product-characteristic__value')\n",
    "            value = value.get_text().strip()\n",
    "\n",
    "            data[key] = value\n",
    "\n",
    "        page_links = [url, *map(lambda x: scheme + x['href'], description.select('a'))]\n",
    "        data['URL'] = page_links\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # get abstract\n",
    "    abstract = soup.select(selectors['abstract'])\n",
    "    data['Описание'] = '-'\n",
    "    try:\n",
    "        for element in abstract:\n",
    "            data['Описание'] += element.get_text()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # get the price block\n",
    "    side_bar = soup.select_one(selectors['side_bar'])\n",
    "    availability = '-'\n",
    "    price = '-'\n",
    "\n",
    "    try:\n",
    "        availability = side_bar.select_one('div').get_text().strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        price = side_bar.select_one('div[itemprop=offers] > span.app-price.product-sidebar-price__price')\n",
    "        price = price.get_text().strip().split()[0]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # get the vendor block\n",
    "    vendor_code = soup.select_one(selectors['vendor_code']).text.strip().split()[-1]\n",
    "\n",
    "    # get rating (local, NOT livelib)\n",
    "    rating = soup.select_one(selectors['rating'])\n",
    "    main_text = '0'\n",
    "    additional_text = '0'\n",
    "    try:\n",
    "        main_text = rating.select_one('span.rating-widget__main-text').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        additional_text = rating.select_one('span.rating-widget__other-text').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    data['Наличие товара'] = availability\n",
    "    data['Цена'] = price\n",
    "    data['Артикул'] = vendor_code\n",
    "    data['Оценка'] = main_text.replace(',','.')\n",
    "    data['Количество оценок'] = additional_text.replace(')', '').replace('(','')\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of pages\n",
    "def get_number_of_pages(search_url, params):\n",
    "    soup = get_soup(search_url, params=params)\n",
    "    search_description = soup.select_one('div.search-page__desc').text\n",
    "    pattern = re.compile(r'[0-9]+')\n",
    "    all_books = int(re.search(pattern, search_description).group(0))\n",
    "\n",
    "    books_per_page = 30\n",
    "    total_pages = all_books // books_per_page + int(all_books % books_per_page != 0)\n",
    "\n",
    "    return total_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'нил гейман'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = 'https://book24.ru/search/page-1/'\n",
    "scheme = 'https://book24.ru'\n",
    "\n",
    "out_put_query_name = query.capitalize().replace(' ', '_')\n",
    "file_name = f'{out_put_query_name}.json'\n",
    "\n",
    "gathered_data = []\n",
    "params = {'q': query}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da52432226c4bc1871caf5557867917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Page: 1/7. Book:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecffd64611741949192476d9838e01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Page: 2/7. Book:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad2682b11004b2ca8022357ad15bd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Page: 3/7. Book:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f374ecbf526f45abb86ae624f9541c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Page: 4/7. Book:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80aa20f506244540938bf48dccf9ff3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Page: 5/7. Book:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4e3dfa71b74ee19f4389675d6b01ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Page: 6/7. Book:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73788dc06444a32acc037b1f9b92519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Page: 7/7. Book:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file: Нил_гейман.json ready!\n"
     ]
    }
   ],
   "source": [
    "def get_data(search_url, params):\n",
    "    total_pages = get_number_of_pages(search_url, params)\n",
    "    page_pbar = tqdm(range(1, total_pages + 1), desc='Page', disable=True, ncol=75)\n",
    "\n",
    "    for page_number in page_pbar:\n",
    "        search_url = f'https://book24.ru/search/page-{page_number}/'\n",
    "        soup = get_soup(search_url, params=params)\n",
    "        book_links = get_books_links_from_page(soup, scheme)\n",
    "\n",
    "        book_pbar = tqdm(book_links, desc=f'Page: {page_number}/{total_pages}. Book', disable=False)\n",
    "        for book_link in book_pbar:\n",
    "            book_soup = get_soup(book_link)\n",
    "            gathered_data.append(get_single_book_data(book_soup, book_link, scheme))\n",
    "        \n",
    "\n",
    "    with open(f'{file_name}', 'w', encoding='utf-8') as f:\n",
    "        json.dump(gathered_data, f, indent=4, ensure_ascii=False)\n",
    "    print(f'JSON file: {file_name} ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parsingEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
